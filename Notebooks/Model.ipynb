{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, GRU, Embedding, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from preprocessing_utlis import normalize\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv('./Names web dataset/all_data_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle Data\n",
    "df_clean = shuffle(df_clean)\n",
    "\n",
    "train, test = train_test_split(df_clean, test_size=0.3,random_state=42, stratify=df_clean['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sz = 800\n",
    "tok = Tokenizer(num_words=vocab_sz, oov_token='UNK')\n",
    "tok.fit_on_texts(train['clean_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tok.texts_to_sequences(train['Names'])\n",
    "X_test = tok.texts_to_sequences(test['Names'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max([len(t) for t in train['Names']])\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3620, 26), (1552, 26))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded = np.array(pad_sequences(X_train,\n",
    "                          maxlen=maxlen,\n",
    "                          padding='post',\n",
    "                          truncating='post'))\n",
    "\n",
    "X_test_padded = np.array(pad_sequences(X_test,\n",
    "                          maxlen=maxlen,\n",
    "                          padding='post',\n",
    "                          truncating='post'))\n",
    "\n",
    "X_train_padded.shape, X_test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train['label']).astype('float32')\n",
    "y_test = np.asarray(test['label']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_sz+1, embedding_size, mask_zero=True, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(units = 32)))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/5\n",
      "29/29 [==============================] - 19s 162ms/step - loss: 0.6753 - accuracy: 0.6724 - val_loss: 0.6413 - val_accuracy: 0.7384\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 0.5477 - accuracy: 0.8326 - val_loss: 0.4011 - val_accuracy: 0.9182\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - 2s 53ms/step - loss: 0.2751 - accuracy: 0.9381 - val_loss: 0.2172 - val_accuracy: 0.9336\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - 2s 53ms/step - loss: 0.1914 - accuracy: 0.9478 - val_loss: 0.2124 - val_accuracy: 0.9336\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - 2s 55ms/step - loss: 0.1858 - accuracy: 0.9481 - val_loss: 0.2106 - val_accuracy: 0.9336\n"
     ]
    }
   ],
   "source": [
    "callbacks_lst = [EarlyStopping(monitor='val_accuracy', mode='max', patience=2)]\n",
    "# Training\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "print('Train...')\n",
    "history = model.fit(X_train_padded, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,          \n",
    "          validation_data=(X_test_padded, y_test),\n",
    "        #   callbacks=callbacks_lst\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Fake Name' , 'Valid Name']\n",
    "def classify(sentence):\n",
    "\n",
    "  sentence = [normalize(sent) for sent in sentence]\n",
    "\n",
    "  sequence = tok.texts_to_sequences(sentence)\n",
    "  sequence = pad_sequences(sequence, maxlen=maxlen, padding='post', truncating='post')\n",
    "  pred = model.predict(sequence)[0][0]\n",
    "  print(class_names[np.round(pred).astype('int')], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "Valid Name 0.98991346\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Fake Name 0.07966373\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Valid Name 0.99031186\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Fake Name 0.07966373\n"
     ]
    }
   ],
   "source": [
    "tst_sent = ['محمد السعيد خليفه']\n",
    "classify(tst_sent)\n",
    "classify(['باسمم وحةد السد'])\n",
    "classify(['باسم وحيد السيد'])\n",
    "classify(['يشسبة كخسيشبىن سيبش'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../saved_model/tria2.h5')\n",
    "with open('../saved_model/tokenizer2.pickle', 'wb') as f:\n",
    "    pickle.dump(tok, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2a43ac65bee716d097253c4c6830512c8998ddb7bca5639cb1bc715f5e041c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
